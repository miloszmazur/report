In this thesis, we aimed to answer the question:  ``How selfish and utilitarian behaviors between artificial agents influence the learning efficiency in task-oriented environments?''.

In order to simulate the agents' motivations, we designed a task that could be solved while puting agents against each other or allowing them to work together, while being simple enough for the results to be readable and for the optimal solution easily imaginable. We then designed a way to grade them, simulating a cooperative or competitive environment working against (or teamed with) a static opponent. Finally, we performed experiments on a bigger scale to see how the two approaches compare. To perform the comparison itself, we defined succes criteria based on our emirical data gathered so far. The algorithms in a competitive scenario produced a successful specimen after 100 generations in 50\% of the cases. The algorithms teaching competitive agents, however, achieved 78\% success rate after the same number of generations. Examining the size component, we noted 70\% success rate across the results from the cooperative case, with 22\% of the algorithm runs fulfilling that criteron in competitive scenario.

Based on the results, we can conclude that the speed at which the two approaches progress differs between stages of learning - changing it pace after certain local optima. Given the fact that the near-optimal solution observed is smaller than in cooperative scenario, we expected it to evolve sooner and in a greater numbers - that, however, did not happen.

We consider comparing the two approaches the main contribution of this work. Additionally, while achieving the thesis goal, we created a reliable platform for experiments using Genetic Programming and Behavior Trees, both separately and together. The effects of problematic areas in joining Behavior Tress with Genetic programming were partly contained by adding additional clauses to tree generation and crossover.

Future work will attempt to verify and expand on the results achieved in this thesis, especially in matters of increasing the scale of reseach and defining proper error measurements to confirm or disprove our current results. That said, the work here merely touches the surface of genetically evolving Behavior Trees and the behavior types they might exhibit. A direction we intend to focus on is a deeper analysis of the population - with greater insight on what structure do the specimen tend to create in various stages of the algorithm, it might be possible to incorporate the group selection ideas based on kinship or similarity of the specimen, mentioned in \cite{cooperationevolution}. Furthermore, developing more sophisticated methods of crossover and mutation, aware of constraints of Behavior Tree encoding, would naturally increase the effectiveness of evolving such trees. The concept of adaptation of the agent to a given environment should also be explored. The task considered in this thesis - arguably simple - has ben proven to be solvable with the simpliest of elements. A natural next step would be increasing both the dificultness of the problem and the resources available to the algorithm.
